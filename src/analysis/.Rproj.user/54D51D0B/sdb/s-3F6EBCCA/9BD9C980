{
    "collab_server" : "",
    "contents" : "################################################\n#      Introducción a la Ciencia de Datos      #\n#           COMPARATIVA DE ALGORITMOS          #\n#                                              #\n# (C) Cristian González Guerrero               #\n################################################\n\n# Build the workspace\nsource(\"../regression/build-workspace.R\")\n\nabalone.tra = lapply(abalone.tra, add.non.linearities)\nabalone.tst = lapply(abalone.tst, add.non.linearities)\n\n\n# Comparison of data points\n\nmyModel = Rings ~\n  Length + \n  Height + \n  Whole_weight.log * \n  Shucked_weight.log * \n  Viscera_weight * \n  Shell_weight.3\n\nmyTrain = abalone.tra[[1]]\nmyTest  = abalone.tst[[1]][sample(1:nrow(abalone.tst[[1]]), 20), ]\n\n## Linear regression\n# Plot some points of the last model\nmyFit = lm(myModel, myTrain)\nmyResult = predict(myFit, myTest)\n\nmyData1 = myTest\nmyData1$Rings = myResult\nmyData1 = cbind(myData1, data.type = \"prediction\", method = \"Linear Model\")\nmyData1 = rbind(myData1, cbind(myTest, data.type = \"original value\", method = \"Linear Model\"))\nmyData1 = melt.data.frame(\n  data = myData1,\n  id.vars = c(\"Shell_weight\", \"data.type\", \"method\"),\n  measure.vars = \"Rings\"\n)\n\n## k-NN\n# Plot some points of the last model\nmyResult = kknn(myModel, myTrain, myTest, k = 7)\n\nmyData2 = myTest\nmyData2$Rings = myResult$fitted.values\nmyData2 = cbind(myData2, data.type = \"prediction\", method = \"k-NN\")\nmyData2 = rbind(myData2, cbind(myTest, data.type = \"original value\", method = \"k-NN\"))\nmyData2 = melt.data.frame(\n  data = myData2,\n  id.vars = c(\"Shell_weight\", \"data.type\", \"method\"),\n  measure.vars = \"Rings\"\n)\n\n\n## Plot\nmyData = rbind(myData1, myData2)\n\nggplot(myData, aes(x = Shell_weight, y = value, color = data.type)) + \n  geom_point() + \n  ylab(\"Rings\") +\n  xlab(\"Shell weight\") + \n  geom_line(aes(group = Shell_weight, color = \"error\")) +\n  labs(color = \"Data type\") + \n  facet_wrap( ~ method, ncol = 1)\n\n\n# Error distribution\nmyTest = abalone.tst[[1]]\nlmErrors  = myTest$Rings-predict(myFit, myTest)\nknnErrors = myTest$Rings-kknn(myModel, myTrain, myTest)$fitted.values\n\nmyData1 = data.frame(method = \"Linear Model\", Err = lmErrors)\nmyData2 = data.frame(method = \"k-NN\", Err = knnErrors)\nmyData = melt.data.frame(\n  data = rbind(myData1, myData2),\n  id.vars = \"method\"\n)\n\n### Tests\nwilcox.test(lmErrors^2, knnErrors^2, paired = FALSE)\nks.test(lmErrors^2, knnErrors^2)\n\n### Plot\nggplot(myData, aes(x=value^2)) + \n  geom_density(aes(color = method, fill = method), alpha = 0.3) +\n  xlab(\"Squared error\") + xlim(0,20)\n\n\n# General algorithm comparison (using MSE from every database)\n## Read data\ntestResults = read.csv(\"../regression/regr_test_alumnos.csv\")\ntestTable = testResults[, 2:ncol(testResults)]\nrownames(testTable) = testResults[,1]\n\ntrainResults = read.csv(\"../regression/regr_train_alumnos.csv\")\ntrainTable = trainResults[, 2:ncol(testResults)]\nrownames(trainTable) = trainResults[,1]\n\n## Comparison between LM and kNN \n## (kNN is assumed to provide better results)\ndifs = (testTable[,1] - testTable[,2])/testTable[,1]\n\nwilc_1_2 = cbind(\n  ifelse(difs<0, abs(difs)+0.1, 0.1),\n  ifelse(difs>0, abs(difs)+0.1, 0.1)\n)\ncolnames(wilc_1_2) = colnames(testTable)[1:2]\n\n### Wikcoxon tests\nLMvsKNNtst = wilcox.test(\n  wilc_1_2[,1], \n  wilc_1_2[,2], \n  alternative = \"two.sided\", \n  paired = TRUE\n)\n\nRplus  = LMvsKNNtst$statistic\npvalue = LMvsKNNtst$p.value\n\nLMvsKNNtst = wilcox.test(\n  wilc_1_2[,2], \n  wilc_1_2[,1], \n  alternative = \"two.sided\", \n  paired = TRUE\n)\n\nRminus = LMvsKNNtst$statistic\n\nWilcoxonTestOutput = cbind(Rplus, Rminus, pvalue)\n\n\n## Comparison amongst LM, kNN and M5'\nfriedman.test(as.matrix(testTable))\n\n#### p-value < 0.05 => significative difference exist\n\ngroups = rep(1:ncol(testTable), each = nrow(testTable))\npairwise.wilcox.test(\n  as.matrix(testTable), \n  groups, \n  p.adjust.method = \"holm\", \n  paired = TRUE\n)\n\n#### M5' seems to work better (confidence: 84%)\n#### LM and kNN seems not to present any difference\n",
    "created" : 1502884131026.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "899583618",
    "id" : "9BD9C980",
    "lastKnownWriteTime" : 1503070545,
    "last_content_update" : 1503070545760,
    "path" : "/home/cristian10/workspace/master/icd/final/src/regression/comparison.R",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}